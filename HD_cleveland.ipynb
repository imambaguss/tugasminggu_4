{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imambaguss/tugasminggu_4/blob/main/HD_cleveland.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Pengumpulan Data"
      ],
      "metadata": {
        "id": "Jx9SThj3klrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Masuk ke laman UCI Machine Learning Repository atau https://archive.ics.uci.edu/\n",
        "2. Cari dan unduh dataset heart disease\n",
        "3. Dari banyak file di dalam dataset heart disease, kita menggunakan cleveland.data untuk diolah dan heart-disease.names untuk penjelasan dan arahan dari pengunggah dataset"
      ],
      "metadata": {
        "id": "H_ZkQ7m8vBLr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Menelaah Data"
      ],
      "metadata": {
        "id": "OYxkOi9ukfkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Di sini dataset awal berisi dataset yang tidak rapi, tidak ada baris dan kolom. Untuk mempermudah membaca dan menganalisis data, kita gunakan itertools untuk membuat kolom. Satu barisnya memiliki 76 kolom."
      ],
      "metadata": {
        "id": "0sIKCvLTvyrj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cazcNMlpjO5U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "direct = '/content/sample_data/cleveland.data'"
      ],
      "metadata": {
        "id": "bKiFGOFrjXjS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(direct, encoding='Latin1') as file:\n",
        "  lines= [line.strip() for line in file]\n",
        "\n",
        "lines[0:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "9TJDgySZjhk3",
        "outputId": "f003f25e-29d3-46e0-bb39-2400991b988f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/cleveland.data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b66ac3fa97ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Latin1'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/cleveland.data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = itertools.takewhile(\n",
        "    lambda x: len(x) == 76,\n",
        "    (' '.join(lines[i:(i+10)]).split() for i in range(0, len(lines), 10))\n",
        ")\n",
        "\n",
        "df = pd.DataFrame.from_records(data)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4zzXWl9xjjzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "SeY6ElM1kwOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,:-1]\n",
        "df = df.drop(df.columns[0], axis =1)"
      ],
      "metadata": {
        "id": "3AeqoZ_IkzlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.astype(float)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "LQV0SqHnk3EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) Validasi Data"
      ],
      "metadata": {
        "id": "Ghniz4CKlZ8w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk memvalidasi data, kita ubah terlebih dahulu nilai -9.0 (yaitu nilai null), menjadi value null atau NaN dengan metode `df.replace`. Setelah mengubah nilai null, kita cek lagi dengan `df.info()` untuk melihat informasi seperti apa saja kolom yang ada, berapa jumlah nilai pada tiap kolom, dan type data masing-masing kolom.\n",
        "\n"
      ],
      "metadata": {
        "id": "nnxqc1mS0eH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengganti nilai -9.0 menjadi null atau NaN karena -9.0 adalah nilai null\n",
        "df.replace(-9.0, np.nan, inplace=True)\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "-xs_pJAPlZC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "EDO5Va7tlicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8oWauEaxlo8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) Menentukan Objek Data"
      ],
      "metadata": {
        "id": "lUN3DawUltBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam heart-disease.names sudah ditentukan kolom mana saja yang akan digunakan nanti, sisanya akan di-drop.\n",
        "Kolom atau atribut yang digunakan:\n",
        "\n",
        "-- 1. #3  (age)       \n",
        "-- 2. #4  (sex)       \n",
        "-- 3. #9  (cp)        \n",
        "-- 4. #10 (trestbps)  \n",
        "-- 5. #12 (chol)      \n",
        "-- 6. #16 (fbs)       \n",
        "-- 7. #19 (restecg)   \n",
        "-- 8. #32 (thalach)   \n",
        "-- 9. #38 (exang)     \n",
        "-- 10. #40 (oldpeak)   \n",
        "-- 11. #41 (slope)     \n",
        "-- 12. #44 (ca)        \n",
        "-- 13. #51 (thal)      \n",
        "-- 14. #58 (num)  \n",
        "\n",
        "Kolom2 yang digunakan ini penting untuk perhitungan kondisi jantung nantinya"
      ],
      "metadata": {
        "id": "p857jkjF14A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected = df.iloc[:, [1, 2, 7, 8, 10, 14, 17, 30, 36, 38, 39, 42, 49, 56]]\n",
        "df_selected.head()"
      ],
      "metadata": {
        "id": "YvqtsplXlr8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected.info()"
      ],
      "metadata": {
        "id": "rqgv4XXol3r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_mapping = {\n",
        "    2: 'age',\n",
        "    3: 'sex',\n",
        "    8: 'cp',\n",
        "    9: 'trestbps',\n",
        "    11: 'chol',\n",
        "    15: 'fbs',\n",
        "    18: 'restecg',\n",
        "    31: 'thalach',\n",
        "    37: 'exang',\n",
        "    39: 'oldpeak',\n",
        "    40: 'slope',\n",
        "    43: 'ca',\n",
        "    50: 'thal',\n",
        "    57: 'target'\n",
        "}\n",
        "df_selected.rename(columns=column_mapping, inplace=True)\n",
        "df_selected.info()"
      ],
      "metadata": {
        "id": "rxg_2j3fmJYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected.value_counts()"
      ],
      "metadata": {
        "id": "njztGyUkmSqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) Membersihkan Data"
      ],
      "metadata": {
        "id": "MYgXse5kmYqb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "langkah2 yang diambil untuk membersihkan data:\n",
        "1. Cek tiap kolom apakah ada nilai null, jika ada maka drop kolom yang terdapat nilai null. Biasanya kolom yang memiliki 100 atau lebih jumlah nilai yang null.\n",
        "2. Jika hanya sedikit nilai null-nya, lakukan perhitungan nilai mean pada kolom yang ada nilai null-nya. Pertama drop terlebih dahulu kolom yang ingin dicari nilai mean-nya. Kedua ubah tipe datanya menjadi float. Ketiga hitung nilai mean beserta dibulatkan. Keempat masukan kembali kolom tadi, ke dalam kolom utama."
      ],
      "metadata": {
        "id": "mwwbrsX42sef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected.isnull().sum()"
      ],
      "metadata": {
        "id": "TfnWXdoomdbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_selected.head(10)"
      ],
      "metadata": {
        "id": "0i19XgO5n6MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop kolom yg ingin dihitung nilai mean-nya\n",
        "meanCa = df_selected['ca'].dropna()\n",
        "meanThal = df_selected['thal'].dropna()\n",
        "\n",
        "# Ubah ke tipe float\n",
        "meanCa = meanCa.astype(float)\n",
        "meanThal = meanThal.astype(float)\n",
        "\n",
        "# Bulatkan bilangannya\n",
        "meanCa = round(meanCa.mean())\n",
        "meanThal = round(meanThal.mean())"
      ],
      "metadata": {
        "id": "vMfiig9hnlfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fill_values = {'ca': meanCa, 'thal': meanThal}\n",
        "dfClean = df_selected.fillna(value=fill_values)\n",
        "dfClean.info()"
      ],
      "metadata": {
        "id": "fBQ2VmKInnZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfClean.isnull().sum()"
      ],
      "metadata": {
        "id": "kSlJfvAxno2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows = dfClean.duplicated()\n",
        "dfClean[duplicate_rows]"
      ],
      "metadata": {
        "id": "5ffG8h74o8VK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfClean.head(10)"
      ],
      "metadata": {
        "id": "mgd2NRAgpJlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfClean['target'].value_counts()"
      ],
      "metadata": {
        "id": "QgTqEsm3pMVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mencari korelasi antar fitur\n",
        "dfClean.corr()"
      ],
      "metadata": {
        "id": "9xvQtO_kpQjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cor_mat = dfClean.corr()\n",
        "fig,ax = plt.subplots(figsize=(15,10))\n",
        "sns.heatmap(cor_mat, annot=True, linewidths=0.5, fmt=\".3f\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "jD77tFsypV2g",
        "outputId": "1704ba99-4d67-48bc-f21c-c5efdf39bfb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dfClean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-c7970efa88df>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcor_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfClean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcor_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\".3f\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dfClean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) Konstruksi Data"
      ],
      "metadata": {
        "id": "YnBrTqxwpadj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam tahap ini Konstruksi data salah satu tujuannya yaitu untuk menyesuaikan semua tipe data yang ada di dalam dataset. Namun pada tahap ini dataset sudah memiliki tipe data yang sesuai sehingga tidak perlu dilakukan penyesuaian kembali dan tidak ada penambahan fitur untuk meningkatkan performa model"
      ],
      "metadata": {
        "id": "CEwkbG--38pN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) Menentukan Label Data"
      ],
      "metadata": {
        "id": "0H_NRJPgqutf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menentukan label data dilakukan untuk memisahkan kolom atribut dan kolom target/class/label. Kita pisahkan terlebih dahulu kolomnya untuk x adalah kolom yang akan dilakukan perhitungan, dan y adalah kolom target. Kolom target ini akan dicek apakah jumlah labelnya mengalami imbalance atau jumlah nilai yang tidak seimbang pada tiap labelnya. Jika mengalami imbalance, maka kita gunakan metode oversampling dengan algoritma SMOTE. Dan nanti hasilnya jumlah setiap label akan sama rata."
      ],
      "metadata": {
        "id": "hai3n9Bg57ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfClean.info()"
      ],
      "metadata": {
        "id": "ngR7WBFHpc27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dfClean.drop(\"target\", axis=1).values\n",
        "y = dfClean.iloc[:, -1]\n",
        "\n",
        "# Visualisasi target\n",
        "dfClean['target'].value_counts().plot(kind='bar',figsize=(10,6),color=['green','blue'])\n",
        "plt.title(\"Count of the target\")\n",
        "plt.xticks(rotation=0);"
      ],
      "metadata": {
        "id": "v1we5aLQpim3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# oversampling\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote_resampled, y_smote_resampled = smote.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "kKkyozRdpp2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat visual plot target sebelum SMOTE\n",
        "plt.subplot(1, 2, 1)\n",
        "new_df1 = pd.DataFrame(data=y)\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "new_df1.value_counts().plot(kind='bar',figsize=(10,6),color=['green', 'blue', 'red', 'yellow'])\n",
        "plt.title(\"target before over sampling with SMOTE \")\n",
        "plt.xticks(rotation=0);\n",
        "\n",
        "# Membuat visual plot target setelah SMOTE\n",
        "plt.subplot(1, 2, 2)\n",
        "new_df2 = pd.DataFrame(data=y_smote_resampled)\n",
        "\n",
        "new_df2.value_counts().plot(kind='bar',figsize=(10,6),color=['green','blue','red','yellow'])\n",
        "plt.title(\"target after over sampling with SMOTE\")\n",
        "plt.xticks(rotation=0);\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g91XjnRypu3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df1 = pd.DataFrame(data=y)\n",
        "print(\"Sebelum SMOTE :\")\n",
        "new_df1.value_counts()"
      ],
      "metadata": {
        "id": "z0YFvT08pw_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nSetelah SMOTE :\")\n",
        "new_df2 = pd.DataFrame(data=y_smote_resampled)\n",
        "new_df2.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "DXftHcOmqBu8",
        "outputId": "19476b0f-b8e9-4585-d978-f3f7f919f7a9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Setelah SMOTE :\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_smote_resampled' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8f8cdad51669>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nSetelah SMOTE :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_smote_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_df2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_smote_resampled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfClean.describe()"
      ],
      "metadata": {
        "id": "uLTCQNhsqJo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada deskripsi diatas dapat dilihat bahwa terdapat rentang nilai yang cukup jauh pada standar deviasi setiap fitur dataset yang kita miliki. Oleh karena itu perlu dilakukan normalisasi/standarisasi agar memperkecil rentang antara standar deviasi setiap kolom."
      ],
      "metadata": {
        "id": "SjmQOoFYqTL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_smote_resampled_normal = scaler.fit_transform(X_smote_resampled)"
      ],
      "metadata": {
        "id": "KtLK4G8-qKy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_smote_resampled_normal)"
      ],
      "metadata": {
        "id": "Pudr3VJhqOdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfcek1 = pd.DataFrame(X_smote_resampled_normal)\n",
        "dfcek1.describe()"
      ],
      "metadata": {
        "id": "i07EOx3wqQIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah dilakukan normalisasi pada fitur, selanjutnya kita perlu membagi fitur dan target menjadi data train dan test."
      ],
      "metadata": {
        "id": "QA919o6ZqmSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) Model"
      ],
      "metadata": {
        "id": "l2RDWUZY5DN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pemisahan data training dan data testing dilakukan 2 kali, yang pertama untuk oversample saja, dan kedua untuk oversample + normalisasi.\n",
        "Perbandingan yang digunakan adalah 80:20, 80% untuk data training, dan 20% untuk data testing.\n",
        "\n",
        "Model yang digunakan adalah k-Nearest Neighbours, Random Forest, dan XGBoost\n",
        "\n",
        "Ada 3 metode dan masing2 metode menggunakan model yang sama, yg pertama adalah Oversample, kedua oversample + normalisasi, dan ketiga oversample + normalisai + Tunning.\n",
        "\n",
        "Masing2 metode akan dihitung confusion matrix-nya (akurasi, presisi, recall, dan f1-score)"
      ],
      "metadata": {
        "id": "VhVOdrYrqy8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# membagi fitur dan target menjadi data train dan test (untuk yang oversample saja)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_smote_resampled, y_smote_resampled, test_size=0.2, random_state=42,stratify=y_smote_resampled)\n",
        "\n",
        "# membagi fitur dan target menjadi data train dan test (untuk yang oversample + normalization)\n",
        "X_train_normal, X_test_normal, y_train_normal, y_test_normal = train_test_split(X_smote_resampled_normal, y_smote_resampled, test_size=0.2, random_state=42,stratify = y_smote_resampled)"
      ],
      "metadata": {
        "id": "kNWrcDwkqmwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,recall_score,f1_score,precision_score,roc_auc_score,confusion_matrix,precision_score\n",
        "\n",
        "def evaluation(Y_test,Y_pred):\n",
        "  acc = accuracy_score(Y_test,Y_pred)\n",
        "  rcl = recall_score(Y_test,Y_pred,average = 'weighted')\n",
        "  f1 = f1_score(Y_test,Y_pred,average = 'weighted')\n",
        "  ps = precision_score(Y_test,Y_pred,average = 'weighted')\n",
        "  metric_dict={'accuracy': round(acc,3),\n",
        "    'recall': round(rcl,3),\n",
        "    'F1 score': round(f1,3),\n",
        "    'Precision score': round(ps,3)\n",
        "  }\n",
        "  return print(metric_dict)"
      ],
      "metadata": {
        "id": "8E3P-_oHqz6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "Cdisorvkq6iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 3)\n",
        "knn_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MT8K5Z_nq4DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_knn = knn_model.predict(X_test)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "print(\"K-Nearest Neighbors (KNN) Model:\")\n",
        "accuracy_knn_smote = round(accuracy_score(y_test,y_pred_knn),3)\n",
        "print(\"Accuracy:\", accuracy_knn_smote)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))"
      ],
      "metadata": {
        "id": "E_mD__TErI8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test,y_pred_knn)"
      ],
      "metadata": {
        "id": "LxfXdcRirTM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada visualisasi ini ditampilkan visualisasi confusion matrix untuk membandingkan hasil prediksi model dengan nilai sebenarnya."
      ],
      "metadata": {
        "id": "2UFi35p_rZwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_knn)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qScEgzHerVwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "yV2InsZyrde0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita akan membangun model dengan algoritma random forest dengan n_estimators yaitu 100, n_estimators sendiri berguna mengatur jumlah pohon keputusan yang akan dibangun"
      ],
      "metadata": {
        "id": "fC7fNlvUrwo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "6rwfjsEMrfBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "accuracy_rf_smote = round(accuracy_score(y_test, y_pred_rf),3)\n",
        "print(\"Accuracy:\",accuracy_rf_smote)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "kGFmQUjlriWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test,y_pred_rf)"
      ],
      "metadata": {
        "id": "-p2AI8GmrlP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xZw4vzrLrlk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "ZnpPNxrhrqjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini dalam membangun model, kita akan menggunakan algoritma XGBoost dengan learning rate yaitu 0.1. learning rate berguna untuk mengontrol seberapa besar kita menyesuaikan bobot model."
      ],
      "metadata": {
        "id": "ek-6Jv_YruXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(learning_rate=0.1, n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "MSk_HUKCro53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "print(\"\\nXGBoost Model:\")\n",
        "accuracy_xgb_smote = round(accuracy_score(y_test, y_pred_xgb),3)\n",
        "print(\"Accuracy:\",accuracy_xgb_smote)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_xgb))"
      ],
      "metadata": {
        "id": "3UBhh91Ir1i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test,y_pred_xgb)"
      ],
      "metadata": {
        "id": "ixEuhcqUr52D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred_xgb)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rdVYWrWXr8J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversample + Normalisasi"
      ],
      "metadata": {
        "id": "7H0y939TsBoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada bagian ini kita akan membuat sebuah model yang dimana data yang dipakai kali ini yang sudah dilakukan oversample dan normalisasi.\n",
        "Algoritma yang digunakan sama seperti sebelumnya yaitu KNN, Random Forest, dan XGBoost. Sekaligus dibuat visualisasi hasil evaluasi pada\n",
        "masing-masing model."
      ],
      "metadata": {
        "id": "D6ca8SCJsBhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "MXTrNlnFsLlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
        "knn_model.fit(X_train_normal, y_train_normal)"
      ],
      "metadata": {
        "id": "GBi32CH3sJ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_knn = knn_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "print(\"K-Nearest Neighbors (KNN) Model:\")\n",
        "accuracy_knn_smote_normal = round(accuracy_score(y_test_normal,y_pred_knn),3)\n",
        "print(\"Accuracy:\", accuracy_knn_smote_normal)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_knn))"
      ],
      "metadata": {
        "id": "tftmFXuWsPp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_knn)"
      ],
      "metadata": {
        "id": "AJNwWtLCsTk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_knn)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_tMJPwoIsV-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "henZacwbsX8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_normal, y_train_normal)"
      ],
      "metadata": {
        "id": "2jBpuW09sdVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "accuracy_rf_smote_normal = round(accuracy_score(y_test_normal, y_pred_rf),3)\n",
        "print(\"Accuracy:\",accuracy_rf_smote_normal )\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_rf))"
      ],
      "metadata": {
        "id": "E8cAt6gYsgka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_rf)"
      ],
      "metadata": {
        "id": "FtQFiLywsjU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_rf)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3F06VepdsmDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "FPLUSCfLsbEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(learning_rate=0.1, n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train_normal, y_train_normal)"
      ],
      "metadata": {
        "id": "fmiezVXdspwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "print(\"\\nXGBoost Model:\")\n",
        "accuracy_xgb_smote_normal = round(accuracy_score(y_test_normal, y_pred_xgb),3)\n",
        "print(\"Accuracy:\",accuracy_xgb_smote_normal)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_xgb))"
      ],
      "metadata": {
        "id": "2vxQ4GxfsqPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_xgb)"
      ],
      "metadata": {
        "id": "n7auj-lBsvbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_xgb)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8bZr3tDesvPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Oversample + Normalisasi + Tunning"
      ],
      "metadata": {
        "id": "wVDB-O73s0EN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada pembuatan model kali ini masih menggunakan algoritma yang sama (KNN, Random Forest, dan XGBoost), namun data yang digunakan\n",
        "adalah data yang sudah dilakukan TunNIng Parameter, Normalisasi, dan Oversample."
      ],
      "metadata": {
        "id": "kGGA7uaztDea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "tfEz3iQ8tOhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setiap parameter tunnning tidak selalu sama karena bergantung pada algoritma yang digunakan.**"
      ],
      "metadata": {
        "id": "uhhtJDGytTr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN"
      ],
      "metadata": {
        "id": "go3MlxOAtEhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "param_grid = {\n",
        "  \"n_neighbors\": range(3, 21),\n",
        "  \"metric\": [\"euclidean\", \"manhattan\", \"chebyshev\"],\n",
        "  \"weights\": [\"uniform\", \"distance\"],\n",
        "  \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\"],\n",
        "  \"leaf_size\": range(10, 61),\n",
        "}\n",
        "\n",
        "knn_model = RandomizedSearchCV(estimator=knn_model, param_distributions=param_grid, n_iter=100, scoring=\"accuracy\", cv=5)\n",
        "\n",
        "knn_model.fit(X_train_normal, y_train_normal)\n",
        "\n",
        "best_params = knn_model.best_params_\n",
        "print(f\"Best parameters: {best_params}\")"
      ],
      "metadata": {
        "id": "RBLMjgQgtLcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_knn = knn_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the KNN model\n",
        "print(\"K-Nearest Neighbors (KNN) Model:\")\n",
        "accuracy_knn_smote_normal_Tun = round(accuracy_score(y_test_normal,y_pred_knn),3)\n",
        "print(\"Accuracy:\", accuracy_knn_smote_normal_Tun)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_knn))"
      ],
      "metadata": {
        "id": "XSg5mhLctb4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_knn)"
      ],
      "metadata": {
        "id": "DWPZDqQNth4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_knn)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5oKXXFLttkje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "K_VPGu5otFUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "  \"n_estimators\": [100, 200],\n",
        "  \"max_depth\": [ 10, 15],\n",
        "  \"min_samples_leaf\": [1, 2],\n",
        "  \"min_samples_split\": [2, 5],\n",
        "  \"max_features\": [\"sqrt\", \"log2\"],\n",
        "  # \"random_state\": [42, 100, 200]\n",
        "}\n",
        "\n",
        "rf_model = RandomizedSearchCV(rf_model, param_grid, n_iter=100, cv=5, n_jobs=-1)\n",
        "\n",
        "rf_model.fit(X_train_normal, y_train_normal)\n",
        "\n",
        "best_params = rf_model.best_params_\n",
        "print(f\"Best parameters: {best_params}\")"
      ],
      "metadata": {
        "id": "5byUm7ZgtnBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rf = rf_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\nRandom Forest Model:\")\n",
        "accuracy_rf_smote_normal_Tun = round(accuracy_score(y_test_normal, y_pred_rf),3)\n",
        "print(\"Accuracy:\",accuracy_rf_smote_normal_Tun)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_rf))"
      ],
      "metadata": {
        "id": "Ld3B3V-7tm2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_rf)"
      ],
      "metadata": {
        "id": "T7OJdQmhtmnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_knn)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "czuuksWbttB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "4aYgqmlMtE5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier()\n",
        "\n",
        "param_grid = {\n",
        "  \"max_depth\": [3, 5, 7],\n",
        "  \"learning_rate\": [0.01, 0.1],\n",
        "  \"n_estimators\": [100, 200],\n",
        "  \"gamma\": [0, 0.1],\n",
        "  \"colsample_bytree\": [0.7, 0.8],\n",
        "}\n",
        "\n",
        "xgb_model = RandomizedSearchCV(xgb_model, param_grid, n_iter=10, cv=5, n_jobs=-1)\n",
        "\n",
        "xgb_model.fit(X_train_normal, y_train_normal)\n",
        "\n",
        "best_params = xgb_model.best_params_\n",
        "print(f\"Best parameters: {best_params}\")"
      ],
      "metadata": {
        "id": "YYRFFygntzTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_xgb = xgb_model.predict(X_test_normal)\n",
        "\n",
        "# Evaluate the XGBoost model\n",
        "print(\"\\nXGBoost Model:\")\n",
        "accuracy_xgb_smote_normal_Tun = round(accuracy_score(y_test_normal, y_pred_xgb),3)\n",
        "print(\"Accuracy:\",accuracy_xgb_smote_normal_Tun)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_normal, y_pred_xgb))"
      ],
      "metadata": {
        "id": "_JYhRbENtzLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(y_test_normal,y_pred_xgb)"
      ],
      "metadata": {
        "id": "YV_DEwIBtzBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test_normal, y_pred_xgb)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('True')\n",
        "plt.ylabel('Predict')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "epuGEPtYty59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9) Evaluasi"
      ],
      "metadata": {
        "id": "oDY8KQlNuULE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita akan melakukan evaluasi data sekaligus membandingkan antar algoritma guna dengan tujuan mengetahui jenis model\n",
        "algoritma yang menghasilkan hasil akurasi terbaik."
      ],
      "metadata": {
        "id": "syvPWSbpuYf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_comp1 = pd.DataFrame({'Model': ['K-Nearest Neighbour','Random Forest',\n",
        "                                      'XGBoost'], 'Accuracy': [accuracy_knn_smote*100,\n",
        "                                                               accuracy_rf_smote*100,accuracy_xgb_smote*100]})\n",
        "\n",
        "model_comp1.head()"
      ],
      "metadata": {
        "id": "ydIf9nrluPvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat bar plot dengan keterangan jumlah\n",
        "fig, ax = plt.subplots()\n",
        "bars = plt.bar(model_comp1['Model'], model_comp1['Accuracy'], color=['red', 'green', 'blue'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Oversample')\n",
        "plt.xticks(rotation=45, ha='right') # Untuk memutar label sumbu x agar lebih mudah dibaca\n",
        "\n",
        "# Menambahkan keterangan jumlah di atas setiap bar\n",
        "for bar in bars:\n",
        "  yval = bar.get_height()\n",
        "  plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ycger2i8ufhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp2 = pd.DataFrame({'Model': ['K-Nearest Neighbour','Random Forest',\n",
        "                                      'XGBoost'], 'Accuracy': [accuracy_knn_smote_normal*100,\n",
        "                                                               accuracy_rf_smote_normal*100,accuracy_xgb_smote_normal*100]})\n",
        "\n",
        "model_comp2.head()"
      ],
      "metadata": {
        "id": "GsZAPoiNul7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat bar plot dengan keterangan jumlah\n",
        "fig, ax = plt.subplots()\n",
        "bars = plt.bar(model_comp2['Model'], model_comp2['Accuracy'], color=['red', 'green', 'blue'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Normalization + Oversampling')\n",
        "plt.xticks(rotation=45, ha='right') # Untuk memutar label sumbu x agar lebih mudah dibaca\n",
        "\n",
        "# Menambahkan keterangan jumlah di atas setiap bar\n",
        "for bar in bars:\n",
        "  yval = bar.get_height()\n",
        "  plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3d-mNXGauniL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_comp3 = pd.DataFrame({'Model': ['K-Nearest Neighbour','Random Forest',\n",
        "                                      'XGBoost'], 'Accuracy': [accuracy_knn_smote_normal_Tun*100,\n",
        "                                                               accuracy_rf_smote_normal_Tun*100,accuracy_xgb_smote_normal_Tun*100]})\n",
        "\n",
        "model_comp3.head()"
      ],
      "metadata": {
        "id": "qE-PLhIqupmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat bar plot dengan keterangan jumlah\n",
        "fig, ax = plt.subplots()\n",
        "bars = plt.bar(model_comp3['Model'], model_comp3['Accuracy'], color=['red', 'green', 'blue'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Normalization + Oversampling + Tunning')\n",
        "plt.xticks(rotation=45, ha='right') # Untuk memutar label sumbu x agar lebih mudah dibaca\n",
        "\n",
        "# Menambahkan keterangan jumlah di atas setiap bar\n",
        "for bar in bars:\n",
        "  yval = bar.get_height()\n",
        "  plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Y9qzv_Sursl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data frame\n",
        "model_compBest = pd.DataFrame({\n",
        "    'Model': ['K-Nearest Neighbour OverSample Tunning', 'Random Forest OverSample',\n",
        "              'XGB OverSample Standarization Tunning'],\n",
        "    'Accuracy': [accuracy_knn_smote_normal_Tun*100, accuracy_rf_smote_normal*100,\n",
        "                 accuracy_xgb_smote_normal_Tun*100]\n",
        "})\n",
        "\n",
        "# Membuat bar plot dengan keterangan jumlah\n",
        "fig, ax = plt.subplots()\n",
        "bars = plt.bar(model_compBest['Model'], model_compBest['Accuracy'], color=['red', 'green', 'blue'])\n",
        "plt.xlabel('Model')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Best Model Comparison')\n",
        "plt.xticks(rotation=45, ha='right') # Untuk memutar label sumbu x agar lebih mudah dibaca\n",
        "\n",
        "# Menambahkan keterangan jumlah di atas setiap bar\n",
        "for bar in bars:\n",
        "  yval = bar.get_height()\n",
        "  plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sYnMN8dwuupH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10) Kesimpulan"
      ],
      "metadata": {
        "id": "az69Ht188Sza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penelitian di atas menggunakan model KNN, Random Forest, dan XGBoost. Sebelum melakukan modeling, terjadi imbalance pada dataset dan harus diperbaiki. Untuk memperbaikinya dengan metode oversampling algoritma SMOTE, hasilnya jumlah nilai pada setiap label sama rata semua.\n",
        "\n",
        "Tingkat akurasi yang didapat tiap model adalah:\n",
        "1.   Oversample\n",
        "*   KNN : 70%\n",
        "*   Random Forest : 94%\n",
        "*   XGBoost : 88%\n",
        "\n",
        "2.   Oversample + Normalisasi\n",
        "*   KNN : 82%\n",
        "*   Random Forest : 94%\n",
        "*   XGBoost : 88%\n",
        "\n",
        "3.   Oversample + Normalisasi + Tunning\n",
        "*   KNN : 89%\n",
        "*   Random Forest : 94%\n",
        "*   XGBoost : 89%\n",
        "\n"
      ],
      "metadata": {
        "id": "gSnzYZMU8deg"
      }
    }
  ]
}